{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c573a94",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-02-12T03:05:03.096112Z",
     "iopub.status.busy": "2023-02-12T03:05:03.095554Z",
     "iopub.status.idle": "2023-02-12T03:05:04.414892Z",
     "shell.execute_reply": "2023-02-12T03:05:04.413577Z"
    },
    "papermill": {
     "duration": 1.329042,
     "end_time": "2023-02-12T03:05:04.418159",
     "exception": false,
     "start_time": "2023-02-12T03:05:03.089117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gc\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89480361",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T03:05:04.426814Z",
     "iopub.status.busy": "2023-02-12T03:05:04.426152Z",
     "iopub.status.idle": "2023-02-12T03:05:29.767432Z",
     "shell.execute_reply": "2023-02-12T03:05:29.766399Z"
    },
    "papermill": {
     "duration": 25.348658,
     "end_time": "2023-02-12T03:05:29.770291",
     "exception": false,
     "start_time": "2023-02-12T03:05:04.421633",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = pd.read_pickle('/kaggle/input/amex-imputed-aggregate-data/X_train_agg.pkl', compression='gzip')\n",
    "y = pd.read_pickle('/kaggle/input/amex-imputed-aggregate-data/y_train_agg.pkl', compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949279e6",
   "metadata": {
    "papermill": {
     "duration": 0.002733,
     "end_time": "2023-02-12T03:05:29.776388",
     "exception": false,
     "start_time": "2023-02-12T03:05:29.773655",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Function to calculate competition's evaluation metric: https://www.kaggle.com/code/inversion/amex-competition-metric-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f6112a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T03:05:29.784460Z",
     "iopub.status.busy": "2023-02-12T03:05:29.783812Z",
     "iopub.status.idle": "2023-02-12T03:05:29.797499Z",
     "shell.execute_reply": "2023-02-12T03:05:29.796583Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.020787,
     "end_time": "2023-02-12T03:05:29.800043",
     "exception": false,
     "start_time": "2023-02-12T03:05:29.779256",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def amex_metric(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "\n",
    "    def top_four_percent_captured(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        df = (pd.concat([y_true, y_pred], axis='columns')\n",
    "              .sort_values('prediction', ascending=False))\n",
    "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "        four_pct_cutoff = int(0.04 * df['weight'].sum())\n",
    "        df['weight_cumsum'] = df['weight'].cumsum()\n",
    "        df_cutoff = df.loc[df['weight_cumsum'] <= four_pct_cutoff]\n",
    "        return (df_cutoff['target'] == 1).sum() / (df['target'] == 1).sum()\n",
    "        \n",
    "    def weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        df = (pd.concat([y_true, y_pred], axis='columns')\n",
    "              .sort_values('prediction', ascending=False))\n",
    "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "        df['random'] = (df['weight'] / df['weight'].sum()).cumsum()\n",
    "        total_pos = (df['target'] * df['weight']).sum()\n",
    "        df['cum_pos_found'] = (df['target'] * df['weight']).cumsum()\n",
    "        df['lorentz'] = df['cum_pos_found'] / total_pos\n",
    "        df['gini'] = (df['lorentz'] - df['random']) * df['weight']\n",
    "        return df['gini'].sum()\n",
    "\n",
    "    def normalized_weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        y_true_pred = y_true.rename(columns={'target': 'prediction'})\n",
    "        return weighted_gini(y_true, y_pred) / weighted_gini(y_true, y_true_pred)\n",
    "\n",
    "    g = normalized_weighted_gini(y_true, y_pred)\n",
    "    d = top_four_percent_captured(y_true, y_pred)\n",
    "\n",
    "    return 0.5 * (g + d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab39d514",
   "metadata": {
    "papermill": {
     "duration": 0.002747,
     "end_time": "2023-02-12T03:05:29.806080",
     "exception": false,
     "start_time": "2023-02-12T03:05:29.803333",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Generating the model\n",
    "\n",
    "Optimizing the LogisticRegression() model doesn't produce significantly greater results than the baseline model (M = 0.77398). However, when tuning it was found that adjusting the following hyperparameters produced a validation set M score around 0.78:\n",
    "\n",
    "* Validation set size = .25\n",
    "* max_iter = 290\n",
    "* C = 100\n",
    "\n",
    "In the below code you can set `target_m_score` to produce a model with your desired quality, but the highest this model has gotten was M = 0.78461"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d1d4375",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T03:05:29.814143Z",
     "iopub.status.busy": "2023-02-12T03:05:29.813462Z",
     "iopub.status.idle": "2023-02-12T03:18:46.304306Z",
     "shell.execute_reply": "2023-02-12T03:18:46.302919Z"
    },
    "papermill": {
     "duration": 796.500781,
     "end_time": "2023-02-12T03:18:46.309761",
     "exception": false,
     "start_time": "2023-02-12T03:05:29.808980",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M = 0.7777403584554738\n",
      "M = 0.7785878733511965\n",
      "M = 0.7755595549618177\n",
      "M = 0.7791411409124813\n",
      "M = 0.7781054348791435\n",
      "M = 0.7738045863649347\n",
      "M = 0.7844621833516792\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93     85180\n",
      "           1       0.82      0.79      0.80     29549\n",
      "\n",
      "    accuracy                           0.90    114729\n",
      "   macro avg       0.87      0.86      0.87    114729\n",
      "weighted avg       0.90      0.90      0.90    114729\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m_score = 0\n",
    "target_m_score = 0.784\n",
    "final_model = None\n",
    "\n",
    "# loop through different iterations of LogisticRegression() model until a model with expected M score is produced\n",
    "while m_score < target_m_score:\n",
    "    # add validation with train_test_split since aggregate data is not time series based\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=.25)\n",
    "    \n",
    "    model = LogisticRegression(max_iter=290, C=100)\n",
    "    model = model.fit(X_train, y_train)\n",
    "    \n",
    "    # use predict_proba() for M score and predict() for classification_report()\n",
    "    proba_preds = model.predict_proba(X_val)[:, 1]\n",
    "    preds = model.predict(X_val)\n",
    "    \n",
    "    # calculate M score on validation set \n",
    "    m_score = amex_metric(pd.DataFrame(y_val), pd.DataFrame(proba_preds, index=y_val.index, columns=[\"prediction\"]))\n",
    "    final_model = model\n",
    "    \n",
    "    print(f'M = {m_score}')\n",
    "    \n",
    "    # show classification report for final model \n",
    "    if m_score >= target_m_score:\n",
    "        print('\\n', classification_report(y_val, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c71cb39",
   "metadata": {
    "papermill": {
     "duration": 0.003081,
     "end_time": "2023-02-12T03:18:46.316316",
     "exception": false,
     "start_time": "2023-02-12T03:18:46.313235",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Saving and using the model to predict on test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20c7ecb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T03:18:46.324759Z",
     "iopub.status.busy": "2023-02-12T03:18:46.324330Z",
     "iopub.status.idle": "2023-02-12T03:18:46.330959Z",
     "shell.execute_reply": "2023-02-12T03:18:46.329827Z"
    },
    "papermill": {
     "duration": 0.013626,
     "end_time": "2023-02-12T03:18:46.333301",
     "exception": false,
     "start_time": "2023-02-12T03:18:46.319675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pickle.dump(final_model, open('logistic_regression_model.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e82379e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T03:18:46.342254Z",
     "iopub.status.busy": "2023-02-12T03:18:46.341789Z",
     "iopub.status.idle": "2023-02-12T03:19:39.368036Z",
     "shell.execute_reply": "2023-02-12T03:19:39.366899Z"
    },
    "papermill": {
     "duration": 53.033903,
     "end_time": "2023-02-12T03:19:39.370928",
     "exception": false,
     "start_time": "2023-02-12T03:18:46.337025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test = pd.read_pickle('/kaggle/input/amex-imputed-aggregate-data/X_test_agg.pkl', compression='gzip')\n",
    "\n",
    "submission = pd.DataFrame(final_model.predict_proba(X_test)[:, 1], index=X_test.index, columns=['prediction'])\n",
    "\n",
    "# index needs to be removed from submission csv\n",
    "submission = submission.reset_index()\n",
    "submission.to_csv('logistic_regression_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 888.265779,
   "end_time": "2023-02-12T03:19:40.600441",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-02-12T03:04:52.334662",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
