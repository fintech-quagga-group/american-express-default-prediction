{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pickle\nimport gc\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-02-12T07:28:41.459220Z","iopub.execute_input":"2023-02-12T07:28:41.459865Z","iopub.status.idle":"2023-02-12T07:28:42.321870Z","shell.execute_reply.started":"2023-02-12T07:28:41.459744Z","shell.execute_reply":"2023-02-12T07:28:42.320561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = pd.read_pickle('/kaggle/input/amex-imputed-aggregate-data/X_train_agg.pkl', compression='gzip')\ny = pd.read_pickle('/kaggle/input/amex-imputed-aggregate-data/y_train_agg.pkl', compression='gzip')","metadata":{"execution":{"iopub.status.busy":"2023-02-12T07:28:42.324741Z","iopub.execute_input":"2023-02-12T07:28:42.325872Z","iopub.status.idle":"2023-02-12T07:29:06.863190Z","shell.execute_reply.started":"2023-02-12T07:28:42.325821Z","shell.execute_reply":"2023-02-12T07:29:06.861721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Function to calculate competition's evaluation metric: https://www.kaggle.com/code/inversion/amex-competition-metric-python","metadata":{}},{"cell_type":"code","source":"def amex_metric(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n\n    def top_four_percent_captured(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n        df = (pd.concat([y_true, y_pred], axis='columns')\n              .sort_values('prediction', ascending=False))\n        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n        four_pct_cutoff = int(0.04 * df['weight'].sum())\n        df['weight_cumsum'] = df['weight'].cumsum()\n        df_cutoff = df.loc[df['weight_cumsum'] <= four_pct_cutoff]\n        return (df_cutoff['target'] == 1).sum() / (df['target'] == 1).sum()\n        \n    def weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n        df = (pd.concat([y_true, y_pred], axis='columns')\n              .sort_values('prediction', ascending=False))\n        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n        df['random'] = (df['weight'] / df['weight'].sum()).cumsum()\n        total_pos = (df['target'] * df['weight']).sum()\n        df['cum_pos_found'] = (df['target'] * df['weight']).cumsum()\n        df['lorentz'] = df['cum_pos_found'] / total_pos\n        df['gini'] = (df['lorentz'] - df['random']) * df['weight']\n        return df['gini'].sum()\n\n    def normalized_weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n        y_true_pred = y_true.rename(columns={'target': 'prediction'})\n        return weighted_gini(y_true, y_pred) / weighted_gini(y_true, y_true_pred)\n\n    g = normalized_weighted_gini(y_true, y_pred)\n    d = top_four_percent_captured(y_true, y_pred)\n\n    return 0.5 * (g + d)","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-02-12T07:29:06.865284Z","iopub.execute_input":"2023-02-12T07:29:06.865734Z","iopub.status.idle":"2023-02-12T07:29:06.881858Z","shell.execute_reply.started":"2023-02-12T07:29:06.865700Z","shell.execute_reply":"2023-02-12T07:29:06.880583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Generating the model\n","metadata":{}},{"cell_type":"code","source":"m_score = 0\ntarget_m_score = 0.81\nfinal_model = None\n\ncount = 0\n\n# loop through different iterations of LogisticRegression() model until a model with expected M score is produced\nwhile m_score < target_m_score and count < 200:\n    # add validation with train_test_split since aggregate data is not time series based\n    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=.25)\n    \n    model = RandomForestClassifier(max_depth=500)\n    model = model.fit(X_train, y_train)\n    \n    # use predict_proba() for M score and predict() for classification_report()\n    proba_preds = model.predict_proba(X_val)[:, 1]\n    preds = model.predict(X_val)\n    \n    # calculate M score on validation set \n    m_score = amex_metric(pd.DataFrame(y_val), pd.DataFrame(proba_preds, index=y_val.index, columns=[\"prediction\"]))\n    final_model = model\n    \n    print(f'M = {m_score}')\n    \n    count = count + 1\n    \n    # show classification report for final model \n    if m_score >= target_m_score:\n        print('\\n', classification_report(y_val, preds))","metadata":{"execution":{"iopub.status.busy":"2023-02-12T07:29:06.883562Z","iopub.execute_input":"2023-02-12T07:29:06.883950Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Saving and using the model to predict on test set ","metadata":{}},{"cell_type":"code","source":"pickle.dump(final_model, open('random_forest_classifier_model.sav', 'wb'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test = pd.read_pickle('/kaggle/input/amex-imputed-aggregate-data/X_test_agg.pkl', compression='gzip')\n\nsubmission = pd.DataFrame(final_model.predict_proba(X_test)[:, 1], index=X_test.index, columns=['prediction'])\n\n# index needs to be removed from submission csv\nsubmission = submission.reset_index()\nsubmission.to_csv('random_forest_classifier_submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}